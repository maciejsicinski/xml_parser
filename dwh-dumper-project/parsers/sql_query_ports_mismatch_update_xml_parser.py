import os
import xml.etree.ElementTree as ET
import sqlglot
from sqlglot import exp
from sqlglot.dialects.bigquery import BigQuery
from sqlglot.dialects.teradata import Teradata

# Folder path to scan
folder_path = "../xml_metadata"
teradata_metadata_path = "../teradata_metadata_extract"

# Output directory path
translated_folder_path = "../sql_extract/bq_based_queries"
output_dir_path = "../sql_extract/teradata_based_queries"
errors_dir_path = "../sql_extract/errors"
xml_output_dir = "../xml_metadata_out"

# Create the output directory if it doesn't exist
os.makedirs(output_dir_path, exist_ok=True)
os.makedirs(errors_dir_path, exist_ok=True)
os.makedirs(translated_folder_path, exist_ok=True)
os.makedirs(xml_output_dir, exist_ok=True)

def bulkTranslate():
    """
    Translated SQL queries from the input folder and save the output queries in a output folder.

    Uses Bulk Translate CLI from GCP.

    Parameters
    ----------
    tbd: tbd
        rbd

    Returns
    -------
    bool
        True if successful, False otherwise.                    
    """
    

    print("translated")

def saveSqlQueryToFile(folder_name, mapping_name, transformation_name, ttype, output_path, query):
    """
    Saves a SQL query to a file.

    The name of the file consists of specific XML components divided by "#". The structure is as follows
    folder_name#mapping_name#transformation_name#ttype.sql
    Parameters
    ----------
    folder_name : (str)
        String with the folder name.
    mapping_name : (str)
        String with the mapping name.
    transformation_name : (str)
        String with the transformation name.
    ttype : (str)
        String with the transformation type.
    output_path : (str)
        Path to the output directory.
    query : (str)
        SQL query to be saved.
    Returns
    -------
    bool
        True if successful, False otherwise.                    
    """
    output_file_name = f"{folder_name}#{mapping_name}#{transformation_name}#{ttype}.sql"
    output_file_name = output_file_name.replace(" ", "")
    output_file_path = os.path.join(output_path, output_file_name)
    with open(output_file_path, "w") as output_file:
        output_file.write(query + "\n")

def replaceLoadIdExp(transformation):
    """
    Modifies EXPRESSION attribute of the TRANSFORMFIELD element. 

    This function adds cast to decimal(5) to the the $$LOAD_ID variable in the expression

    Parameters
    ----------
    transformation : (Element)
        An element of the XML document.

    Returns
    -------
    bool
        True if successful, False otherwise.                    
    """
    if transformation.attrib["TYPE"] == "Expression":
        for field in transformation.iter("TRANSFORMFIELD"):
            expression = field.get("EXPRESSION")
            if expression is not None and expression == "$$LOAD_ID":
                field.attrib["EXPRESSION"] = "TO_DECIMAL($$LOAD_ID,5)"

def updateConnectors(mapping, transformation_name, map):
    """
    Modifies FROMFIELD and TOFIELD attribute of the CONNECTOR element. 

    This function updates FROMFIELD and TOFIELD of the CONNECTOR element to the values generated by the port alignment function

    Parameters
    ----------
    mapping : (Element)
        An element of the XML document
    transformation : (Element)
        An element of the XML document
    map : (dict)
        A dictionary containing mapping of original port values to new values
                    
    Returns
    -------
    bool
        True if successful, False otherwise.  
                    
    """
    for connector in mapping.iter("CONNECTOR"):
        if connector.attrib["FROMINSTANCE"] == transformation_name and connector.attrib["FROMFIELD"] in map.keys():
            old = connector.attrib["FROMFIELD"] #functionalize
            new = map[connector.attrib["FROMFIELD"]]['to']
            if old != new:
                connector.attrib["FROMFIELD"] = map[connector.attrib["FROMFIELD"]]['to']
        elif connector.attrib["TOINSTANCE"] == transformation_name and connector.attrib["TOFIELD"] in map.keys():
            old = connector.attrib["TOFIELD"] #reuse function
            new = map[connector.attrib["TOFIELD"]]['to']
            if old != new:
                connector.attrib["TOFIELD"] = map[connector.attrib["TOFIELD"]]['to']

def updateConflictingPortNames(mapping, transformation_name, new_port, port_names):
    """
    Modifies NAME of the ports identified as duplicates after the port alignment. 

    This function updates NAME of the TRANSFORMFIELD element to the values generated by adding the suffix with the index

    Parameters
    ----------
    mapping : (Element)
        An element of the XML document
    transformation : (Element)
        An element of the XML document
    new_port : (str)
        name of the port that needs to be changed
    port_names : ([str])
        An Array of the connected ports in order to skip unconnected ports
    map : (dict)
        A dictionary containing mapping of original port values to new values

    Returns
    -------
    updated_ports : ([str])
        An array of all updated ports
    conflict_update : (dict)
        A dictionary containing a map from original values to new values
                    
    """
    updated_ports = []
    conflict_update = {}
    for transformation in mapping.iter("TRANSFORMATION"):
        if transformation.attrib["NAME"] == transformation_name:
            for index, port in enumerate(transformation.iter("TRANSFORMFIELD")):
                if new_port == port.attrib["NAME"]:
                    updated_name = port.attrib["NAME"] + "__" + str(index)
                    if port.attrib["NAME"] in port_names:
                        updated_ports.append(updated_name)
                    conflict_update [updated_name] = {
                        "original" : new_port
                    }
                    port.attrib["NAME"] = updated_name
    return updated_ports, conflict_update

def getSqlQuery(transformation):
    """
    Returns a SQL query for a specific transofrmation. 

    Parameters
    ----------
    transformation : (Element): 
        An element of the XML document
    Returns
    -------
    sql_query : (str): 
        A string containing SQL query   
                    
    """
    for ta in transformation.iter("TABLEATTRIBUTE"):
        if ta.attrib["NAME"] == "Sql Query":
            sql_query= ta.attrib["VALUE"]
    return sql_query

def updateSqlQuery(transformation, query):
    """
    Updates a SQL query (based on supplied parameter) for a specific transformation. 

    Parameters
    ----------
    transformation : (Element): 
        An element of the XML document
    query : (str)
        A string containing SQL query  
    Returns
    -------
    bool
        True if successful, False otherwise.  
                    
    """
    for ta in transformation.iter("TABLEATTRIBUTE"):
        if ta.attrib["NAME"] == "Sql Query":
            ta.attrib["VALUE"] = query

def getConnectedFrom(mapping, transformation_name):
    """
    Retrieves and returns a list of the ports connected to the specific transformation. 

    Parameters
    ----------
    mapping : (Element)
        An element of the XML document
    transformation : (Element): 
        An element of the XML document
    Returns
    -------
    connected_from: [str]
        A list of ports connected to this transformation (only from the transformation to the next component).  
                    
    """
    connected_from = []
    for connector in mapping.iter("CONNECTOR"):
        if connector.attrib["FROMINSTANCE"] == transformation_name:
            connected_from.append(connector.attrib["FROMFIELD"])
    return connected_from

def findColumns(query, dialect):
    """
    Retrieves and returns a list of the columns from the supplied SQL query. 

    Parameters
    ----------
    query : (str)
        SQL query to be parsed.
    Returns
    -------
    column_names: [str]
        A list of columns from the supplied SQL query.
                    
    """
    column_names = []
    try:
        for expression in sqlglot.parse(query, dialect)[0].find(exp.Select).args["expressions"]:
            column_names.append(expression.alias_or_name)
    except Exception as e:
        return ["parse_error"] #try to print the error
    return column_names

def extractQueries(filename):
    """
    Retrieves, returns and save a sql query to a file.

    Parameters
    ----------
    filename : (str)
        The name of the file containing .
    Returns
    -------
    column_names: [str]
        A list of columns from the supplied SQL query.
                    
    """
    with open(filename, "r", encoding="iso-8859-1") as fh:
        doc = ET.parse(fh)
        root = doc.getroot()
        for folder in root.iter("FOLDER"):
            folder_name = folder.attrib["NAME"]
            for child in folder.iter("MAPPING"):
                mapping_name = child.attrib["NAME"]
                for sq in child.iter("TRANSFORMATION"):
                    ttype = sq.attrib["TYPE"]
                    transformation_name = sq.attrib["NAME"]
                    if ttype == "Source Qualifier":
                        query = getSqlQuery(sq)
                        if query is not None and len(query) > 0:
                            saveSqlQueryToFile(folder_name, mapping_name, transformation_name, ttype, output_dir_path, query)

def extractSqlQueryFromFile(folder, mapping, transformation, ttype):
    """

    
    The name of the file consists of specific XML components divided by "#". The structure is as follows
    folder_name#mapping_name#transformation_name#ttype.sql

    Yields
    ------
    err_code : int
        Non-zero value indicates error code, or zero on success.
    err_msg : str or None
        Human readable error message, or None on success.
    """
    filename = folder + "#" + mapping + "#" + transformation + "#" + ttype + ".sql"
    filename = filename.replace(" ", "")
    file_path = os.path.join(translated_folder_path, filename)
    try:
        with open(file_path, "r", encoding="iso-8859-1") as fh:
            input_query = fh.read()
            return input_query
    except Exception as e:
        return e


def processFile(filename):
    """
    This function parses through the XML files and modifies its content in order to generate informatica mapping compatible with BigQuery.


    For each transformation get only Sql Query attribute to parse and save columns returned by a SQL query   
    For each transformation in each mapping get only Source Qualifier transformation and save it's port
    Only manipulate ports if they are connected (port is used further down the mapping)
    Don't update if the SQL parser returned an error
    create file with the mapping.sq so we know where the error occured
    Don't update if both lists contains the same values (lowercased)
    Update NAME attribute values 
    Update XML file with modified values
    Write informatica header into a file
    Write modified XML into a out file

    Parameters
    ----------
    filename : str: 
        a path to the XML document (Informatica mapping)
    Returns
    -------
    bool
        True if successful, False otherwise.  

    """
    with open(filename, "r", encoding="iso-8859-1") as fh:
        doc = ET.parse(fh)
        root = doc.getroot()
        for folder in root.iter("FOLDER"):
            folder_name = folder.attrib["NAME"]
            for child in folder.iter("MAPPING"):
                mapping_name = child.attrib["NAME"]
                for sq in child.iter("TRANSFORMATION"):                
                    replaceLoadIdExp(sq)
                    field_dict = {} 
                    conflict_update = {}
                    ttype = sq.attrib["TYPE"]
                    transformation_name = sq.attrib["NAME"]
                    connected_from = getConnectedFrom(child, transformation_name)
                    if ttype == "Source Qualifier":
                        query = getSqlQuery(sq)
                    if ttype == "Source Qualifier" and query is not None and len(query) > 0:     
                        dialect = "Teradata"  
                        translated_query = extractSqlQueryFromFile(folder_name, mapping_name, transformation_name, ttype)      
                        if not isinstance(translated_query, Exception):
                            dialect = "BigQuery" 
                            updateSqlQuery(sq, translated_query)
                            query = getSqlQuery(sq)
                        port_names = []
                        field_nodes = list(sq.iter("TRANSFORMFIELD"))
                        for field in field_nodes:
                                if field.attrib["NAME"] in connected_from:
                                    port_names.append(field.attrib["NAME"])
                        sql_columns = findColumns(query, dialect)
                            # HERE ADD EMPTY ALIASES HANDLING
                        if sql_columns == ["parse_error"]:
                            saveSqlQueryToFile(folder_name, mapping_name, transformation_name, ttype, errors_dir_path, query)
                            continue
                        else:
                            i = 0
                            for field in sq.iter("TRANSFORMFIELD"):
                                if i < len(sql_columns) and field.attrib["NAME"] in port_names:
                                    if sql_columns[i].lower() != field.attrib["NAME"].lower():    
                                        field_dict[field.attrib["NAME"]]= {  
                                        "from": field.attrib["NAME"],
                                         "to" : sql_columns[i]
                                        }
                                        next = sql_columns[i]
                                        updated_ports, conflict_update_tmp = updateConflictingPortNames(
                                            mapping=child,
                                            transformation_name=transformation_name,
                                            new_port=next,
                                            port_names = port_names
                                        )
                                        if conflict_update_tmp:
                                            conflict_update.update(conflict_update_tmp)
                                        for item in updated_ports:
                                            port_names.append(item)
                                        field.attrib["NAME"] = sql_columns[i] 
                                    i+=1
                            field_dict_2 = {}
                            if(conflict_update):
                                for key, value in field_dict.items():
                                    if key in conflict_update:
                                        original_key = conflict_update[key]['original']
                                        field_dict_2[original_key] = value
                                        field_dict_2[original_key]['from'] = original_key
                                    else:
                                        field_dict_2[key] = value
                                for key, value in conflict_update.items():
                                    if key not in field_dict.keys() :
                                        field_dict_2 [conflict_update[key]['original']]= {  
                                        "from": conflict_update[key]['original'],
                                         "to" : key
                                        }
                            else:
                                field_dict_2 = field_dict
                            updateConnectors(child, transformation_name, field_dict_2)
        filename_out = filename + "_OUT.XML"
        with open(filename_out, "w", encoding="iso-8859-1") as fh:
            fh.write("<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n")
            fh.write("<!-- Informatica proprietary -->\n")
            fh.write("<!DOCTYPE POWERMART SYSTEM \"powrmart.dtd\">\n")
            fh.write(ET.tostring(root).decode("iso-8859-1"))


# Main program                                    
# Process each file in the folder and save each sql query to a separate file
for filename in os.listdir(folder_path):
    if filename.endswith(".XML"):
        file_path = os.path.join(folder_path, filename)
        extractQueries(file_path)

# Setup GCP Bulk Translate API and translate the queries

bulkTranslate()

# Process each file in the folder to parse and update the XML's
for filename in os.listdir(folder_path):
    if filename.endswith(".XML"):
        file_path = os.path.join(folder_path, filename)
        processFile(file_path)

